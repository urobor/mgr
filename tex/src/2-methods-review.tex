\chapter{Przegląd wybranych metod detekcji i~identyfikacji
obiektów w~obrazach}

We wstępie zamieszczono krótki opis pojęć detekcji i~identyfikacji.
Jednak ze względu na niejednoznaczności związane z~tymi terminami
zaobserwowane w~literaturze,
artykułach oraz dyskusjach na forach internetowych podjęto próbę
precyzyjnego określenia czym są: detekcja oraz identyfikacja
obiektów w~obrazach. Na potrzeby niniejszej pracy dyplomowej wprowadzone
zostały następujące dwie definicje.

Detekcja obiektów, innymi słowy wykrywanie lub lokalizacja,
polega na określeniu czy i~gdzie obiekt danej klasy występuje w~obrazie.
Jeżeli na obrazie widoczne są szukane obiekty,
produktem procesu powinny być współrzędne wszystkich ich wystąpień.
Przykładami tego typu działań są:

\begin{itemize}
    \item wykrywanie twarzy,
    \item detekcja przechodniów,
    \item lokalizacja tekstu w~scenie itp.
\end{itemize}

Identyfikacja (rozpoznawanie) obiektów polega na przypisaniu
poszczególnym instancjom już wykrytych obiektów odpowiadających im
etykiet. Dostarczone próbki w~założeniu powinny reprezentować
obiekty badanej klasy, czyli analogicznie do zaprezentowanych
przykładów z~dziedziny detekcji były by to: twarze,
znaki drukowane lub (niewymienione wcześniej) odciski palców.
Wynikiem tak zdefiniowanego działania powinny być nazwiska osób
skojarzonych z~twarzami lub odciskami palców,
czy w~przypadku znaków drukowanych odpowiadające im litery, cyfry
itp.

Idealnym podziałem z~punktu widzenia niniejszej pracy byłoby ścisłe
rozdzielenie algorytmów na dwie kategorie:

\begin{enumerate}
    \item Algorytmy odpowiadające na pytanie czy i~ewentualnie gdzie
        w~obrazie
        znajdują się obiekty szukanej klasy (z~uwzględnieniem przesunięcia,
        skalowania i~obrotu), na przykład twarze, znaki drogowe, znaki
        drukowane, samochody, fronty samochodów czy fronty autobusów.
    \item Algorytmy zwracające nazwę, typ lub identyfikator obiektu
        dostarczonego w~postaci określonej wielkości fragmentu obrazu
        w~ustalonej orientacji, na przykład przypisanie twarzy do
        właścicieli, znaku do kodu czy samochodu do marki i~modelu.
\end{enumerate}

Istnieje wiele algorytmów i~implementacji ściśle pasujących do
przedstawionych opisów. Są też jednak takie, które zawierają obie
funkcjonalności, na przykład śledzenie (detekcja) twarzy należącej
do konkretnej (identyfikacja) osoby. Niektóre rozwiązania zaprojektowane
w~celu detekcji po trywialnych modyfikacjach mogą służyć
do rozpoznawania wykrytych obiektów. Ostatecznie niektóre detektory
w~efekcie ubocznym mogą z~powodzeniem identyfikować poszczególne
instancje wykrywanych obiektów.

W~kolejnych podrozdziałach
przedstawiono najpopularniejsze algorytmy, implementacje
oraz koncepcje z~dziedziny detekcji i~identyfikacji obiektów w~obrazach.
Znaczna większość opisanych rozwiązań posiada gotową implementację
w~darmowej bibliotece OpenCV \cite{wiki:opencv}, która powstała
w~ramach projektu
zapoczątkowanego
w~1999 roku przez firmę Intel. W~2012 roku prace wznowiono
a~utrzymanie oraz rozwój powierzono fundacji non-profit
OpenCV.org. Biblioteka udostępniana jest wersjij
stabilnej 2.4.10 z~października 2014 oraz rozwojowej
3.0 BETA planowanej na maj 2014.

Ze względu na licencję BSD, świetną
dokumentację, ciągły aktywny rozwój, implementację na wielu platformach,
w~tym Windwos, Linux oraz Android, jest to pozycja niezastąpiona
przy implementacji rozwiązań nie tylko z~dziedziny identyfikacji
i~detekcji lecz widzenia komputerowego w~ogóle. Dodatkowo nacisk
położony na przetwarzanie obrazów w~czasie rzeczywistym czyni z~biblioteki
OpenCV idealnego kandydata do wykorzystania w~implementacji
programu odczytującego numeru linii z~frontu nadjeżdżającego
autobusu na urządzeniu mobilnym z~systemem Android.

\section{Wykrywanie obiektów - detekcja}

Na potrzeby pracy wprowadzony i~opisany został termin
,,detekcji obiektów''. Na wejściu tak zdefiniowanego detektora
jest obraz zawierający (lub nie) wystąpienia interesujących obiektów, gdzie
wyjściem jest lista przyciętych obrazów reprezentujących wystąpienia tych
obiektów (fizyczne kopie lub współrzędne). W~kolejnych podrozdziałach
przedstawione zostały rozwiązania nawiązujące do powyższego opisu.

\subsection{Klasyfikator kaskadowy oparty na cechach Haara}

Struktura ramowa do wykrywania obiektów zaproponowana w~2001 roku, której
autorami byli Paul Viola i Michael Jones \cite{DBLP:conf/cvpr/ViolaJ01}
była pierwszą tego
rodzaju implementacją umożliwiającą wykrywanie obiektów w~czasie
rzeczywistym przy jednoczesnym zachowaniu wysokiej skuteczności
oferowanego rozwiązania. Algorytm został zaprojektowany z~myślą o~wykrywaniu
twarzy w~obrazie, nie uwzględnione było natomiast ich rozpoznawanie.
Główne jego zalety to m.in.:

\begin{itemize}
\item wysoka skuteczność - duży odsetek pozytywnych trafień przy niewielkiej
ilości błędów,
\item wysoka wydajność - jak wspomniano we wstępie osiągnięto wyniki
rzędu kilkunastu klatek na sekundę dla obrazów wielkości 0.1Mpix na sprzęcie
klasy Pentium III,
\item możliwość przygotowania detektora dla innych obiektów, nie tylko
twarzy.
\end{itemize}

Proces przygotowania (uczenia) detektora jest żmudny i~długotrwały.
Niezbędne jest ręczne oznaczenie wystąpień interesujących obiektów
w~obrazach (lub odpowiednie ich przycięcie). 
Posiadając zbiór składający się z~co najmniej kilku tysięcy elementów,
można uruchomić program trenujący, którego wykonanie, w~zależności
od liczności zbioru i~zadanych parametrów może trwać od kilku minut do 
kilku godzin. W~skrajnych przypadkach gdy zbiór uczący składa
się z~dziesiątek tysięcy elementów, proces uczenia może trwać nawet
kilka dni.

Autorzy pierwotnego rozwiązania wykorzystali zbiór kilku tysięcy
twarzy. Istnieją też opracowania w~których wykorzystano zbiory
liczące do 10 tysięcy elementów \cite{WEB:ocvnaotoshiseo}.

Biblioteka OpenCV zawiera funkcje
do wykrywania obiektów w~językach Java, Python i~C++, oraz zestaw
programów pomocniczych
do przygotowywania
kaskadowych detektorów różnych typów. W~dokumentacji
\cite{OCV:cascadeclassification}
jest mowa o~dwóch opracowaniach \cite{DBLP:conf/cvpr/ViolaJ01,
DBLP:conf/icip/LienhartM02} na których bazuje oferowana
implementacja. Dostarczone narzędzia umożliwiają przygotowanie
detektorów opartych na cechach Haara, HOG 
(\textit{ang. Histogram of Oriented Gradients}) oraz LBP 
(\textit{ang. Local Binary
Pattern}). Zastosowanie ostatniego z~wymienionych zestawu cech umożliwia
znaczne skrócenie czasu potrzebnego do przygotowania detektora.
Co ważne, z~punktu widzenia tejże pracy, tak przygotowany detektor
charakteryzuje się też większą wydajnością, kosztem niewielkiego tylko 
spadku
dokładności, co przy wykorzystaniu odpowiednio dużej liczby próbek
podczas jego uczenia nie powinno mieć znaczenia.

Podstawowa funkcjonalność dostarczana przez implementację została zawarta
w~funkcji \verb|detectMultiScale|\cite{OCV:cascadeclassification}.
Dla przekazanego obrazu (argument wywołania)
zwracana jest kolekcja czworokątów okalających
reprezentująca wystąpienia szukanego obiektu.

Aby jednak skorzystać
ze~wspomnianej funkcji trzeba przygotować plik
definiujący klasyfikator. Jest to proces żmudny o~tyle, iż wymaga
dużej liczby oznaczonych wystąpień szukanych obiektów. Należy dostarczyć
tym dłuższą listę, im większe zróżnicowanie w~obiektach reprezentujących
daną klasę. Jak już wspomniano, liczba oznaczonych próbek
w~przypadku twarzy (lub obiektów o~porównywalnej
różnorodności) powinna wynosić
co najmniej kilka tysięcy. Zbiór obrazów tła (obrazy nie zawierające 
wystąpienia szukanych obiektów)
powinien stanowić około połowę ilości oznaczonych obiektów
\cite{WEB:ocvnaotoshiseodocument}.

Kolejnym czynnikiem jest czas potrzebny na przygotowanie detektora.
Pierwotna metoda oparta na cechach Haara
jest najbardziej intensywna obliczeniowo, a~cały proces uczenia
może trwać do kilku dni. Rozwiązania oparte na innych cechach - LBP
(\textit{ang. Local Binary Pattern}) - ze względu na wykorzystanie
liczb całkowitych zamiast zmiennoprzecinkowych trwają stosunkowo krócej, 
lecz nadal czas wykonania liczony jest w~godzinach.

Samo wyszukiwanie obiektów oparte jest na oknie przesuwnym
(\textit{ang. Sliding Window}). Wspomniane okno przemieszcza się nad
obrazem, definiując kombinację podobrazów dla których po kolei uruchamiany
jest algorytm określający czy dany fragment reprezentuje szukany obiekt.
Ograniczeniem wprowadzonym przez to podejście jest brak możliwości
wykrycia obrotu. Krawędzie okna są bowiem zawsze równoległe z~krawędziami
obrazu. Zaletą jest niewielka złożoność obliczeniowa, która pozwala
na wykrywanie i~lokalizowanie obiektów w~czasie rzeczywistym.

\subsection{Cechy 2D - struktura ramowa biblioteki OpenCV}

Biblioteka OpenCV poza wspomnianym detektorem udostępnia
strukturę ramową do operacji na cechach: ich wyliczanie, opisywanie
i~dopasowywanie \cite{OCV:feture2dframework}.
Tutaj w~odróżnieniu od detektora kaskadowego, zestaw cech
jest wyliczany dla każdego obrazu osobno. Jest to proces dużo bardziej
intensywny obliczeniowo niż w~poprzednim przypadku. Dodatkowo
funkcjonalność detekcji obiektów jest raczej efektem ubocznym,
a~ze względu na jednostkowy charaktery wyszukiwanych obiektów, rozwiązanie
bardziej nadaje się do weryfikacji i~rozpoznawania obiektów niż do
detekcji i~lokalizacji obiektów pewnej klasy. Przykład zastosowania
zaprezentowano poniżej - rysunek \ref{fig:rev_features2d_detection}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.8\textwidth]{img/rev_features2d_detection}
  \caption{Wykorzystanie framework-a cech 2d do wykrywania obiektów}
  \label{fig:rev_features2d_detection}
\end{figure}

Powyższy przykład pokazuje jak trudno zachować podział na wykrywanie
i~rozpoznawanie. Rysunek \ref{fig:rev_features2d_detection}
przedstawia sytuację, w~której wykrycie obiektu jest równoznaczne
z~jego rozpoznaniem.
Algorytm wylicza zestaw cech dla konkretnej okładki, po czym dla każdego
obrazu (w~przypadku pracy w~czasie rzeczywistym) wyliczany
jest dużo większy zestaw cech klatki. Jeżeli znaleziony zostanie
odpowiednio duży podzbiór cech podobnych na obu obrazach to wiadomo,
że obiekt znajduje się w~kadrze.
Dodatkowo, na podstawie ułożenia pasujących cech, możliwe jest
wyznaczenie jego zniekształcenia geometrycznego. W~kontekście wprowadzonego
podziału jest to raczej przykład lokalizacji poszczególnych instancji danej
klasy obiektów, niż wykrywanie obiektów klasy w~ogóle.
Poważnym
ograniczeniem jest wymóg posiadania dużej ilości szczegółów przez 
poszukiwany
obiekt, a~także wysoka rozdzielczość klatek, w~obrębie których odbywa się
poszukiwanie. Złożoność obliczeniowa, a~co za tym idzie czas przeszukiwania
poszczególnych klatek sprawiają, że metoda ta jest mało atrakcyjna w~kontekście
postawionego zadania.

Biblioteka OpenCV, w~omawianym jej fragmencie posiada znacznie
większą niż wspomniana funkcjonalność.
Ze względu na mnogość zaimplementowanych algorytmów - których opis
wykracza poza zakres tego opracowania - istnieje ogromna ilość
zastosowań wspomnianego frameworka. Jednym z~nich jest na przykład
detekcja obszarów
reprezentujących tekst w~scenach naturalnych. W~tym celu
można wykorzystać implementację algorytmu MSER - (\textit{ang. Most
Stable Extreme Regions}) \cite{OCV:MSER}.

\subsection{Open TLD - detekcja i~identyfikacja}

Kolejnym algorytmem łączącym w~sobie funkcje wykrywania
i~rozpoznawania obiektów jest algorytm opracowany przez
Zdenka Kalala \cite{DBLP:journals/pami/KalalMM12} - TLD (\textit{ang.
Track Learn Detect}).

Głównym zadaniem jakie rozwiązuje omawiany algorytm jest śledzenie obiektów.
Pewnym ograniczeniem jest potrzeba pierwszego oznaczenia interesującego
obiektu w~sekwencji obrazów tak aby możliwe było podjęcie pracy.
W~trakcie śledzenia tak oznaczonego obiektu odbywa się uczenie (doskonalenie)
detektora. O~ile sam etap śledzenia nie wykorzystuje detektora, to jest on
niezwykle istotny przy wznowieniu śledzenia po zniknięciu obiektu z~kadru.
Algorytm charakteryzuje się wysoką wydajnością i~zadziwiającą skutecznością.
Co prawda wyniki naocznych eksperymentów i~zamieszczonych przez autorów filmów
demonstracyjnych wyglądają efektownie, jednak bez narzędzi do automatycznego
mierzenia skuteczności trudno stwierdzić jaką klasę niezawodności 
i~skuteczności prezentuje omawiane rozwiązanie.

Kolejną kwestią jest obecność gotowych implementacji.
Dostępna jest co prawda wersja napisana w~języku C/C++ oraz MatLabie.
Niestety brak implementacji w~pakiecie OpenCV lub
innej gotowej wersji dostępnej na system Android jest kolejnym
argumentem przeciwko wykorzystywaniu TLD jako elementu
programu odczytującego numer autobusu na urządzeniu z~systemem Android.
Wymagająca analiza i~naniesienie
niezbędnych modyfikacji,
choć kształcące mogą nie przyczynić się do osiągnięcia zamierzonego celu.

Istnieje także przypuszczenie, że pozostawienie algorytmu w~trybie uczenia,
ze względu na rosnącą liczbę pozytywnych i~negatywnych obiektów w~bazie,
może powodować powolny spadek jego wydajności. Jest to jednak teza 
wymagająca przeprowadzenia rzetelnych testów, które ze względu
na nie wykorzystanie algorytmu w~rozwiązaniu końcowym nie zostały
wykonane.

\section{Rozpoznawanie obiektów - identyfikacja}

Drugim terminem poza detekcją, jest rozpoznawanie obiektów. Algorytm
odpowiedzialny za 
identyfikację najczęściej przyjmuje na wejściu obrazy stałych rozmiarów
\footnote{Co prawda nie jest to wymagane, jednak znacznie ułatwia 
wyliczenie wektora cech przypisanego do każdego zdjęcia, który to 
wektor dla większości popularnych implementacji musi być stałej 
długości.}.
Jego zadaniem jest zwrócenie
tekstu określającego typ, rodzaj lub po prostu nazwę danego obiektu.
Przykładem zastosowania może być odczytanie wykrytych liter,
cyfr, przypisanie twarzy do właścicieli lub zwrócenie marki wykrytego
samochodu.

Ze względu na specyfikę zagadnienia, gotowych implementacji algorytmów
identyfikacji jest niewiele lub sprawdzają się one w~obrębie
ściśle określonego zagadnienia. Niektóre z~przytoczonych w~poprzednim
podrozdziale przykładów mogą równie dobrze służyć jako identyfikatory
obiektów. Algorytm OpenTLD skutecznie rozróżnia twarze, gesty oraz
poszczególne instancje obiektów różnych klas.

Klasycznym podejściem do identyfikacji jest uczenie maszynowe. Na
wejściu podawany jest zbiór reprezentantów poszczególnych klas
z~przypisanymi do nich oczekiwanymi rezultatami. Rozwiązanie
sprawdza się przy rozpoznawaniu znaków drukowanych o~wysokim
kontraście i~w~wysokiej rozdzielczości. Utrudnieniem jest w~tym
przypadku znalezienie odpowiedniego przekształcenia obrazu
wejściowego na wektor cech, który jest właściwym 
parametrem wejściowym omawianej grupy algorytmów. W~skrajnych przypadkach
(np. wspomniane binarne obrazy reprezentujące znaki odpowiednio 
przycięte i~o~stałych rozmiarach) wektor może składać się 
z~wartości poszczególnych pikseli obrazu. W~sytuacjach bardziej 
skomplikowanych, niezbędne jest wstępne przetworzenie obrazu i/lub 
wykorzystanie przekształceń jak na przykład histogramy sum wartości
pikseli w~poszczególnych kolumnach lub wierszach, czy wspomniany
już wcześniej HOG (\textit{ang. Histogram of Oriented Gradients}).

Korzystając z~biblioteki
OpenCV \ można wybrać następujące metody:

\begin{itemize}
    \item model statystyczny,
    \item normalny klasyfikator bayesowski,
    \item k-najbliższych-sąsiadów,
    \item SVM,
    \item drzewa losowe,
    \item drzewa decyzyjne,
    \item sieci neuronowe,
    \item inne.
\end{itemize}

Częścią wspólną przedstawionych metod są fazy
fazy uczenia i~rozpoznawania, w~bibliotece
OpenCV reprezentowane przez funkcje \verb|train|, oraz \verb|predict|.

Niestety wybór metody obliczania wektora cech dla obrazów
pozostaje w~gestii programisty.
Można użyć deskryptorów cech
SIFT, SURF, BRIEF, HOG itp. W~skrajnie laboratoryjnych warunkach, tak
jak w~odczytywaniu znaków czarno-białych, można porównywać poszczególne
piksele. Jeżeli jednak tekst
jest ulokowany w~tak zwanej scenie naturalnej -
szyld, reklama, bilbord itp. - różnice w~czcionkach, refleksy
i~zniekształcenia uniemożliwiają wykorzystanie tak trywialnej metody.

Zagadnienie jest na tyle ważne i~jednocześnie skomplikowane, że
powstał plebiscyt, którego zadaniem jest wyłonienie najlepszego
algorytmu odczytującego teksty ze scen naturalnych. Odbywa się
on co dwa lata, a~ostatnia edycja miała miejsce w~roku 2013.
Zwycięzcy konkursu ICDAR2013 w~dziedzinie odczytywania tekstu ze
zdjęć, do rozpoznawania poszczególnych znaków wykorzystali sieci neuronowe.
Podobnie było w~przypadku algorytmu odczytującego numery domów na potrzeby
geolokalizacji w~usłudze Google:StreetView. Ostatecznie zadanie
odczytywania numerów/tekstów ze zdjęć jest zadaniem najtrudniejszym
z~dotąd omawianych.

\begin{figure}[h!]
    \centering
    \includegraphics[width=0.8\textwidth]{img/rev_captcha_street_view}
    \caption{Przykładowa captcha z prawdopodobnym numerem domu}
    \label{fig:google_street_view_captcha}
\end{figure}

O~skali złożoności problemu może świadczyć fakt, iż
opracowany przez Google algorytm wymaga wspomagania w~postaci
ręcznej interwencji
operatorów. Proces został na wpół zautomatyzowany, 
poprzez wykorzystanie internautów do ręcznego
przepisania numeru domu np. podczas logowani, rejestracji lub innej
czynności wymagającej zabezpieczenia przed szkodliwą działalnością
automatów - rysunek \ref{fig:google_street_view_captcha}.

